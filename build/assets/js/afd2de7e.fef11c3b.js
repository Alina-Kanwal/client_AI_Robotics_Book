"use strict";(globalThis.webpackChunkai_spec_book=globalThis.webpackChunkai_spec_book||[]).push([[941],{8453(n,e,i){i.d(e,{R:()=>r,x:()=>l});var o=i(6540);const t={},s=o.createContext(t);function r(n){const e=o.useContext(s);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:r(n.components),o.createElement(s.Provider,{value:e},n.children)}},8960(n,e,i){i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>l,toc:()=>c});var o=i(4848),t=i(8453);const s={sidebar_position:6},r="Conclusion: Learning Summary and Future Directions",l={id:"conclusion/index",title:"Conclusion: Learning Summary and Future Directions",description:"Synthesis of Key Concepts",source:"@site/docs/conclusion/index.md",sourceDirName:"conclusion",slug:"/conclusion/",permalink:"/docs/conclusion/",draft:!1,unlisted:!1,editUrl:"https://github.com/your-username/physical-ai-humanoid-robotics/edit/main/docs/conclusion/index.md",tags:[],version:"current",sidebarPosition:6,frontMatter:{sidebar_position:6},sidebar:"tutorialSidebar",previous:{title:"Capstone: Autonomous Humanoid (Conceptual Flow)",permalink:"/docs/capstone/"}},a={},c=[{value:"Synthesis of Key Concepts",id:"synthesis-of-key-concepts",level:2},{value:"The Integrated Architecture",id:"the-integrated-architecture",level:3},{value:"The Embodied Intelligence Framework",id:"the-embodied-intelligence-framework",level:3},{value:"Key Learning Outcomes",id:"key-learning-outcomes",level:2},{value:"Technical Competencies Acquired",id:"technical-competencies-acquired",level:3},{value:"Communication and Coordination",id:"communication-and-coordination",level:4},{value:"Simulation and Development",id:"simulation-and-development",level:4},{value:"AI and Perception",id:"ai-and-perception",level:4},{value:"Human-Robot Interaction",id:"human-robot-interaction",level:4},{value:"Conceptual Understanding",id:"conceptual-understanding",level:3},{value:"System Thinking",id:"system-thinking",level:4},{value:"Embodied Cognition",id:"embodied-cognition",level:4},{value:"Safety-First Design",id:"safety-first-design",level:4},{value:"Future Directions and Emerging Trends",id:"future-directions-and-emerging-trends",level:2},{value:"Technological Advancements",id:"technological-advancements",level:3},{value:"AI Integration",id:"ai-integration",level:4},{value:"Hardware Innovation",id:"hardware-innovation",level:4},{value:"Interaction Technologies",id:"interaction-technologies",level:4},{value:"Research Frontiers",id:"research-frontiers",level:3},{value:"Long-Term Challenges",id:"long-term-challenges",level:4},{value:"Ethical and Social Considerations",id:"ethical-and-social-considerations",level:4},{value:"Practical Applications and Impact",id:"practical-applications-and-impact",level:2},{value:"Current Applications",id:"current-applications",level:3},{value:"Future Potential",id:"future-potential",level:3},{value:"Getting Started with Physical AI",id:"getting-started-with-physical-ai",level:2},{value:"Next Steps for Continued Learning",id:"next-steps-for-continued-learning",level:3},{value:"Hands-On Practice",id:"hands-on-practice",level:4},{value:"Building Skills",id:"building-skills",level:4},{value:"Contributing to the Field",id:"contributing-to-the-field",level:3},{value:"Final Reflections",id:"final-reflections",level:2},{value:"Resources for Continued Learning",id:"resources-for-continued-learning",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.h1,{id:"conclusion-learning-summary-and-future-directions",children:"Conclusion: Learning Summary and Future Directions"}),"\n",(0,o.jsx)(e.h2,{id:"synthesis-of-key-concepts",children:"Synthesis of Key Concepts"}),"\n",(0,o.jsx)(e.p,{children:"As we conclude our journey through Physical AI and Humanoid Robotics, let's synthesize the key concepts we've explored across all modules. This comprehensive overview will help solidify your understanding of how these technologies work together to create embodied intelligent systems."}),"\n",(0,o.jsx)(e.h3,{id:"the-integrated-architecture",children:"The Integrated Architecture"}),"\n",(0,o.jsx)(e.p,{children:"Throughout this book, we've examined four foundational pillars that form the backbone of modern humanoid robotics:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"The Robotic Nervous System (ROS 2)"}),": The communication infrastructure enabling different components to work together"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"The Digital Twin (Gazebo & Unity)"}),": Simulation environments for safe development and testing"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"The AI-Robot Brain (NVIDIA Isaac)"}),": Advanced perception and control systems"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Vision-Language-Action (VLA)"}),": Multimodal interfaces for natural human-robot interaction"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"These components work in concert to create robots that can perceive, reason, and act in the physical world."}),"\n",(0,o.jsx)(e.h3,{id:"the-embodied-intelligence-framework",children:"The Embodied Intelligence Framework"}),"\n",(0,o.jsx)(e.p,{children:"The core principle underlying all our discussions is that intelligence emerges from the interaction between cognitive processes and physical embodiment:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Perception    \u2502    \u2502   Cognition     \u2502    \u2502   Action        \u2502\n\u2502                 \u2502    \u2502                 \u2502    \u2502                 \u2502\n\u2502 \u2022 Vision        \u2502\u25c4\u2500\u2500\u25ba\u2502 \u2022 Reasoning     \u2502\u25c4\u2500\u2500\u25ba\u2502 \u2022 Locomotion    \u2502\n\u2502 \u2022 Audio         \u2502    \u2502 \u2022 Planning      \u2502    \u2502 \u2022 Manipulation  \u2502\n\u2502 \u2022 Tactile       \u2502    \u2502 \u2022 Learning      \u2502    \u2502 \u2022 Control       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502                       \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502   Environment   \u2502\n                    \u2502                 \u2502\n                    \u2502 \u2022 Physics       \u2502\n                    \u2502 \u2022 Objects       \u2502\n                    \u2502 \u2022 Humans        \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,o.jsx)(e.p,{children:"This closed loop enables robots to learn from interaction with the physical world, creating more robust and adaptable intelligence."}),"\n",(0,o.jsx)(e.h2,{id:"key-learning-outcomes",children:"Key Learning Outcomes"}),"\n",(0,o.jsx)(e.h3,{id:"technical-competencies-acquired",children:"Technical Competencies Acquired"}),"\n",(0,o.jsx)(e.p,{children:"By completing this book, you now understand:"}),"\n",(0,o.jsx)(e.h4,{id:"communication-and-coordination",children:"Communication and Coordination"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"How ROS 2 enables distributed robotics systems through nodes, topics, services, and actions"}),"\n",(0,o.jsx)(e.li,{children:"The importance of standardized interfaces for system integration"}),"\n",(0,o.jsx)(e.li,{children:"Best practices for designing modular, maintainable robot software"}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"simulation-and-development",children:"Simulation and Development"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"How digital twins enable safe and efficient robot development"}),"\n",(0,o.jsx)(e.li,{children:"The principles of sim-to-real transfer and domain randomization"}),"\n",(0,o.jsx)(e.li,{children:"The role of synthetic data in AI development"}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"ai-and-perception",children:"AI and Perception"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"How GPU acceleration enables real-time perception and decision-making"}),"\n",(0,o.jsx)(e.li,{children:"The integration of vision, language, and action in embodied systems"}),"\n",(0,o.jsx)(e.li,{children:"The architecture of modern AI-powered robotic systems"}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"human-robot-interaction",children:"Human-Robot Interaction"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"How VLA systems enable natural human-robot communication"}),"\n",(0,o.jsx)(e.li,{children:"The challenges of grounding language in physical reality"}),"\n",(0,o.jsx)(e.li,{children:"The importance of safety and reliability in autonomous systems"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"conceptual-understanding",children:"Conceptual Understanding"}),"\n",(0,o.jsx)(e.p,{children:"Beyond technical skills, you now appreciate:"}),"\n",(0,o.jsx)(e.h4,{id:"system-thinking",children:"System Thinking"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"The importance of considering all system components when designing robots"}),"\n",(0,o.jsx)(e.li,{children:"How individual components must work together for effective operation"}),"\n",(0,o.jsx)(e.li,{children:"The trade-offs between performance, safety, and complexity"}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"embodied-cognition",children:"Embodied Cognition"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"How physical embodiment shapes intelligent behavior"}),"\n",(0,o.jsx)(e.li,{children:"The role of action-perception loops in learning and adaptation"}),"\n",(0,o.jsx)(e.li,{children:"The advantages of grounding AI in physical interaction"}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"safety-first-design",children:"Safety-First Design"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"The critical importance of safety in physical AI systems"}),"\n",(0,o.jsx)(e.li,{children:"How simulation enables safe development and testing"}),"\n",(0,o.jsx)(e.li,{children:"The need for robust fallback mechanisms and human oversight"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"future-directions-and-emerging-trends",children:"Future Directions and Emerging Trends"}),"\n",(0,o.jsx)(e.h3,{id:"technological-advancements",children:"Technological Advancements"}),"\n",(0,o.jsx)(e.p,{children:"The field of Physical AI and humanoid robotics continues to evolve rapidly. Key areas of advancement include:"}),"\n",(0,o.jsx)(e.h4,{id:"ai-integration",children:"AI Integration"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Multimodal Foundation Models"}),": Large-scale models that integrate vision, language, and action"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Neuromorphic Computing"}),": Brain-inspired architectures for more efficient processing"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Continual Learning"}),": Systems that continuously adapt and improve over time"]}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"hardware-innovation",children:"Hardware Innovation"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Soft Robotics"}),": More natural and safe human interaction through compliant mechanisms"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Advanced Actuators"}),": Higher fidelity movement and manipulation capabilities"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Energy Efficiency"}),": Extended operational periods and sustainability"]}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"interaction-technologies",children:"Interaction Technologies"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Natural Interfaces"}),": More intuitive and seamless human-robot interaction"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Collaborative Robotics"}),": Safe and effective human-robot teamwork"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Social Robotics"}),": Robots that understand and respond to social cues"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"research-frontiers",children:"Research Frontiers"}),"\n",(0,o.jsx)(e.h4,{id:"long-term-challenges",children:"Long-Term Challenges"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Generalization"}),": Creating robots that can operate effectively in diverse, novel environments"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Learning Efficiency"}),": Enabling rapid learning from limited experience"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Commonsense Reasoning"}),": Incorporating general world knowledge into robot behavior"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Long-Term Autonomy"}),": Maintaining reliable operation over extended periods"]}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"ethical-and-social-considerations",children:"Ethical and Social Considerations"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Trust and Acceptance"}),": Building human confidence in robotic systems"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Privacy and Security"}),": Protecting human privacy and preventing misuse"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Fairness and Accessibility"}),": Ensuring equitable access to robotic benefits"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Human-Robot Coexistence"}),": Designing systems that enhance rather than replace human capabilities"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"practical-applications-and-impact",children:"Practical Applications and Impact"}),"\n",(0,o.jsx)(e.h3,{id:"current-applications",children:"Current Applications"}),"\n",(0,o.jsx)(e.p,{children:"Physical AI and humanoid robotics are already making an impact in:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Healthcare"}),": Assistive robots for elderly care and rehabilitation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Manufacturing"}),": Flexible automation and human-robot collaboration"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Service Industries"}),": Customer service, cleaning, and logistics"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Research"}),": Scientific discovery and space exploration"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"future-potential",children:"Future Potential"}),"\n",(0,o.jsx)(e.p,{children:"The convergence of Physical AI technologies promises to revolutionize:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Domestic Life"}),": Household assistance and companionship"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Education"}),": Interactive learning and tutoring"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Entertainment"}),": Immersive experiences and social interaction"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Disaster Response"}),": Dangerous environment operation and rescue"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"getting-started-with-physical-ai",children:"Getting Started with Physical AI"}),"\n",(0,o.jsx)(e.h3,{id:"next-steps-for-continued-learning",children:"Next Steps for Continued Learning"}),"\n",(0,o.jsx)(e.p,{children:"To continue your journey in Physical AI and humanoid robotics:"}),"\n",(0,o.jsx)(e.h4,{id:"hands-on-practice",children:"Hands-On Practice"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Set up a development environment"})," with ROS 2 and simulation tools"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Experiment with existing robot platforms"})," like TurtleBot, PR2, or commercial robots"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Join the robotics community"})," through forums, conferences, and open-source projects"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Participate in robotics competitions"})," and challenges"]}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"building-skills",children:"Building Skills"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Programming"}),": Strengthen Python, C++, and AI/ML skills"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Mathematics"}),": Deepen understanding of linear algebra, calculus, and probability"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Engineering"}),": Learn about mechanics, electronics, and control systems"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"AI/ML"}),": Explore deep learning, reinforcement learning, and computer vision"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"contributing-to-the-field",children:"Contributing to the Field"}),"\n",(0,o.jsx)(e.p,{children:"The future of Physical AI depends on diverse perspectives and collaborative efforts:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Open Source Contributions"}),": Contribute to ROS 2, simulation tools, and AI libraries"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Interdisciplinary Research"}),": Bridge robotics with cognitive science, psychology, and design"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Ethical Development"}),": Advocate for responsible AI and robotics development"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Education and Outreach"}),": Help others learn about Physical AI and robotics"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"final-reflections",children:"Final Reflections"}),"\n",(0,o.jsx)(e.p,{children:"Physical AI and humanoid robotics represent one of the most exciting frontiers in technology, where digital intelligence comes alive through physical embodiment. The convergence of communication systems, simulation environments, AI capabilities, and natural interaction modalities is creating unprecedented opportunities for human-robot collaboration."}),"\n",(0,o.jsx)(e.p,{children:"As you continue your journey in this field, remember that the most important goal is creating technology that enhances human life while maintaining safety, reliability, and ethical principles. The robots of the future will be partners in our daily lives, and the foundations you've learned in this book will help you contribute to that future."}),"\n",(0,o.jsx)(e.p,{children:"The path from concept to reality in robotics requires persistence, creativity, and collaboration. With the knowledge gained from this book, you're well-equipped to contribute to the exciting developments ahead in Physical AI and humanoid robotics."}),"\n",(0,o.jsx)(e.h2,{id:"resources-for-continued-learning",children:"Resources for Continued Learning"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS 2 Documentation"}),": docs.ros.org"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"NVIDIA Isaac"}),": developer.nvidia.com/isaac"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Robotics Research"}),": IEEE/RSJ conferences and journals"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Open Source Projects"}),": GitHub robotics repositories"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Simulation Tools"}),": Gazebo, Unity Robotics, Isaac Sim documentation"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"The future of embodied AI awaits your contributions!"})]})}function h(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}}}]);